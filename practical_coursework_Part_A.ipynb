{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Practical coursework: COMP6481/8481 2022/23\n",
    "\n",
    "**Anna Jordanous**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "# Part A\n",
    "\n",
    "This notebook contains the questions for Part A of the practical coursework. \n",
    "\n",
    "When you answer these questions, include in your submission for Part A your answers and the code that you used. \n",
    "\n",
    "The most straightforward way to do this is to complete Part A within this Jupyter notebook. *Please add your answers and code per question in the indicated cells.*\n",
    "\n",
    "You can instead submit a separate python file for Part A if this is preferable for you, but remember to include:\n",
    "* your code \n",
    "* comments that: \n",
    " * clearly indicate which question each code snippet relates to, \n",
    " * contain the answer to that question.\n",
    "\n",
    "Part A is worth 20 marks in total. Each question is annotated with the number of marks that question is worth. In each question, half the marks are awarded for the code and half the marks are awarded for correct answers to the question.\n",
    "\n",
    "***Cells are provided for you to complete your answers in this notebook. Please do not edit any of the existing code and markdown already provided in this Jupyter notebook.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important: do this first\n",
    "Run the following cells before attempting the questions.\n",
    "When each cell has completed running successfully, it will print an output message confirming that this cell has finished processing. \n",
    "\n",
    "If you have any issues, log into jupyter.kent.ac.uk and run this notebook on jupyter.kent.ac.uk.\n",
    "\n",
    "To run this notebook initially, you will need to be working with connection to the internet, as it reads files from online sources. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished processing import statements\n"
     ]
    }
   ],
   "source": [
    "#import required/useful libraries\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "\n",
    "print('finished processing import statements')\n",
    "\n",
    "# Note: these packages are all available if you run this notebook on jupyter.kent.ac.uk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished setting up variables and functions for data readin\n"
     ]
    }
   ],
   "source": [
    "#Read in data\n",
    "prefix = \"https://raw.githubusercontent.com/annajordanous/COMP6481-8481/main/\"\n",
    "suffix = \".pdf.txt\"\n",
    "samples = [\"instb\", \"unitb\", \"instw\", \"unitw\"]\n",
    "b_env = [\"TheUniversityofBirmingham\", \"TheUniversityofSheffield\", \"UniversityofNottingham,The\", \n",
    "         \"TheUniversityofLancaster\", \"UniversityofBristol\", \"UniversityofSouthampton\", \n",
    "         \"TheUniversityofManchester\", \"UniversityofDundee\", \"UniversityofYork\"]\n",
    "w_env = [\"AstonUniversity\", \"BirkbeckCollege\", \"LiverpoolJohnMooresUniversity\",\n",
    "         \"ManchesterMetropolitanUniversity\", \"NottinghamTrentUniversity\", \"TheUniversityofHuddersfield\",\n",
    "         \"TheUniversityofWestLondon\", \"UniversityofEastLondon\", \"UniversityofStirling\"]\n",
    "k_env = [\"TheUniversityofKent\"]\n",
    "instb = {}\n",
    "instw = {}\n",
    "instk = {}\n",
    "unitb = {}\n",
    "unitw = {}\n",
    "unitk = {}\n",
    "\n",
    "def readURL(filename):\n",
    "    # open a connection to a URL using urllib\n",
    "    webUrl  = urllib.request.urlopen(filename)\n",
    "    # read the data from the URL and print it\n",
    "    data = webUrl.read()\n",
    "    return data\n",
    "    \n",
    "def readFiles(x, tag):\n",
    "    itag = \"inst\"+tag\n",
    "    filenameI = prefix+itag+\"/\"+itag+x+suffix\n",
    "    utag = \"unit\"+tag\n",
    "    filenameU = prefix+utag+\"/\"+utag+x+\"-11\"+suffix\n",
    "    dataI = str(readURL(filenameI))\n",
    "    dataU = str(readURL(filenameU))\n",
    "    return(dataI, dataU)\n",
    "\n",
    "print(\"finished setting up variables and functions for data readin\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished reading in textual data\n"
     ]
    }
   ],
   "source": [
    "# this cell may take some time to run\n",
    "\n",
    "# read in textual data \n",
    "for x in b_env:\n",
    "    (instb[x], unitb[x]) = readFiles(x, \"b\")\n",
    "    \n",
    "for x in w_env:\n",
    "    (instw[x], unitw[x]) = readFiles(x, \"w\")\n",
    "\n",
    "for x in k_env:\n",
    "    (instk[x], unitk[x]) = readFiles(x, \"k\")\n",
    "    \n",
    "print(\"Finished reading in textual data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished reading in spreadsheet data\n"
     ]
    }
   ],
   "source": [
    "# this cell may take some time to run\n",
    "\n",
    "# read in spreadsheet data \n",
    "docAwards = pd.read_excel('https://github.com/annajordanous/COMP6481-8481/blob/main/sampleData/REF2021Results-SelectedSamples-DoctoralDegreesAwarded.xlsx?raw=true')\n",
    "researchIncome = pd.read_excel('https://github.com/annajordanous/COMP6481-8481/blob/main/sampleData/REF2021Results-SelectedSamples-ResearchIncome.xlsx?raw=true')\n",
    "researchIncomeInKind = pd.read_excel('https://github.com/annajordanous/COMP6481-8481/blob/main/sampleData/REF2021Results-SelectedSamples-ResearchIncomeInKind.xlsx?raw=true')\n",
    "resultsSummary = pd.read_excel('https://github.com/annajordanous/COMP6481-8481/blob/main/sampleData/REF2021Results-SelectedSamples-resultsSummary.xlsx?raw=true')\n",
    "# This file is just for information\n",
    "# https://github.com/annajordanous/COMP6481-8481/blob/main/sampleData/REF2021Results-SelectedSamples-selectionCommentary.xlsx\n",
    "\n",
    "print(\"Finished reading in spreadsheet data\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selected universities for comparison\n",
    "\n",
    "Our `env_better_than_kent` sample of 'Computer Science and Informatics' universities with similar REF outputs performance to Kent but *better* performance in environment is:\n",
    "* The University of Birmingham\n",
    "* The University of Sheffield\n",
    "* University of Nottingham, The\n",
    "* The University of Lancaster\n",
    "* University of Bristol\n",
    "* University of Southampton\n",
    "* The University of Manchester\n",
    "* University of Dundee\n",
    "* University of York\n",
    "\n",
    "Our `env_worse_than_kent` sample of 'Computer Science and Informatics' universities with similar REF outputs performance to Kent but *worse* performance in environment is:\n",
    "* Aston University\n",
    "* Birkbeck College\n",
    "* Liverpool John Moores University\n",
    "* Manchester Metropolitan University\n",
    "* Nottingham Trent University\n",
    "* The University of Huddersfield\n",
    "* The University of West London\n",
    "* University of East London\n",
    "* University of Stirling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The data\n",
    "\n",
    "### data frames\n",
    "\n",
    "* `resultsSummary` gives a summary of all REF results data for the above selected universities and Kent overall, for outputs, for impact and for environment\n",
    "* `docAwards` gives a summary of all REF data for the above selected universities and Kent for the number of doctoral degrees awarded per year at each university\n",
    "* `researchIncome` gives a summary of all REF data for the above selected universities and Kent for the amount of research income (funding) awarded per year at each university\n",
    "* `researchIncomeInKind`  gives a summary of all REF data for the above selected universities and Kent for the amount of research income in kind (non-financial donations that have monetary value) awarded per year at each university\n",
    "\n",
    "\n",
    "### text dictionaries and variables \n",
    "\n",
    "* `instb` is a dictionary of institution statements for the 'env_better_than_kent' sample, with the keys as provided in the list `b_env`: \n",
    " * ['TheUniversityofBirmingham', 'TheUniversityofSheffield', 'UniversityofNottingham,The', 'TheUniversityofLancaster', 'UniversityofBristol', 'UniversityofSouthampton', 'TheUniversityofManchester', 'UniversityofDundee', 'UniversityofYork']\n",
    "\n",
    "* `unitb` is a dictionary of unit statements for the 'env_better_than_kent' sample, with the keys as provided in the list `b_env`: \n",
    " * ['TheUniversityofBirmingham', 'TheUniversityofSheffield', 'UniversityofNottingham,The', 'TheUniversityofLancaster', 'UniversityofBristol', 'UniversityofSouthampton', 'TheUniversityofManchester', 'UniversityofDundee', 'UniversityofYork']\n",
    "\n",
    "* `instw` is a dictionary of institution statements for the 'env_worse_than_kent' sample, with the keys as provided in the list `w_env`: \n",
    " * ['AstonUniversity', 'BirkbeckCollege', 'LiverpoolJohnMooresUniversity', 'ManchesterMetropolitanUniversity', 'NottinghamTrentUniversity', 'TheUniversityofHuddersfield', 'TheUniversityofWestLondon', 'UniversityofEastLondon', 'UniversityofStirling']\n",
    "\n",
    "* `unitw` is a dictionary of unit statements for the 'env_worse_than_kent' sample, with the keys as provided in the list `w_env`: \n",
    " * ['AstonUniversity', 'BirkbeckCollege', 'LiverpoolJohnMooresUniversity', 'ManchesterMetropolitanUniversity', 'NottinghamTrentUniversity', 'TheUniversityofHuddersfield', 'TheUniversityofWestLondon', 'UniversityofEastLondon', 'UniversityofStirling']\n",
    "\n",
    "* `instk` is a dictionary of the (single) institution statement for Kent, with the key as provided in the list `k_env`: \n",
    " * [\"TheUniversityofKent\"]\n",
    "\n",
    "* `unitk` is a dictionary of the (single) unit statement for Kent, with the key as provided in the list `k_env`: \n",
    " * [\"TheUniversityofKent\"]\n",
    "\n",
    "Please refer to the slides for the coursework and the lecture on the coursework from Wednesday 8th March if you would like further explanation of these data and text.\n",
    "\n",
    "### Links\n",
    "\n",
    "All data and text are sourced from https://www.ref.ac.uk/\n",
    "\n",
    "Copies of each of these files are available at https://github.com/annajordanous/COMP6481-8481/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For Part A, we will focus on the unit environment statements for each university in our sample, i.e. the texts in the dictionaries** \n",
    "* `unitb`\n",
    "* `unitw`\n",
    "* `unitk`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some code to help you use the text dictionaries:\n",
    "\n",
    "The following code goes through each of the universities in the `env_better_than_kent` sample, and prints:\n",
    "* the key for that university in the above dictionaries\n",
    "* the first 200 characters of the unit environment statement (i.e. the statement written about the research environment at that Computer Science and Informatics deparatment at that university)\n",
    "* the first 200 characters of the institution environment statement (i.e. the statement written about the research environment across the whole of that university)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for b in b_env:\n",
    "    print(b)\n",
    "    print(unitb[b][0:200])\n",
    "    print(instb[b][0:200])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coursework questions for Part A:\n",
    "\n",
    "For each question, please add your code to the empty code cell below the question, and please add any written answers/comments to the empty markdown cell below the question, as indicated. \n",
    "\n",
    "***You are allowed to add additional code markdown cells as needed below this point. Please do not edit any of the existing code and markdown already provided in this Jupyter notebook.***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Q1. [4 marks] \n",
    "\n",
    "We have defined a measure of `lexical richness` as: the number of unique tokens in a text, divided by the total number of tokens in that text. \n",
    "\n",
    "We have also defined a second measure: how many times, on average, is each token used in the text? \n",
    "\n",
    "*Without doing any additional processing on the texts*, calculate for each university in our data, including Kent,\n",
    "i.e. for all texts in the dictionaries unitb, unitw and unitk:\n",
    "* the lexical richness for the *unit* Environment statements (number of unique tokens in a statement text / the total number of tokens in that statement text)\n",
    "* how many times, on average, is each token used in the statement text\n",
    "\n",
    "Store the results in a new dictionary called `lr` , where the dictionary key is the university key (as in b_env, w_env and k_env), and the value is an ordered *list* of: \n",
    "* the calculated lexical richness for that university's statement text \n",
    "* how many times on average is a word used in that universities statement text?\n",
    "\n",
    "\n",
    "For example, if we have calculated that the unit Environment statement for \"TheUniversityofBirmingham\" has a lexical richness of 12.3, and that on average, tokens in this statement are used 5.5 times, one possible way we could add this to the `lr` dictionary is: \n",
    "\n",
    "`lr[\"TheUniversityofBirmingham\"] = [12.3, 5.5]`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = {}\n",
    "# please add your code for Q1 here (double click to edit)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# please do not delete or edit this cell \n",
    "print(lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2. [4 marks]\n",
    "\n",
    "Create a Pandas data frame called `lr_df` from the dictionary `lr`. \n",
    "\n",
    "Then *transpose* lr_df, so that each row represents a university and the three columns represent the university key names, lexical richness and average token uses, respectively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# please add your code for Q2 here (double click to edit)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# please do not delete or edit this cell \n",
    "lr_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3. [4 marks] \n",
    "\n",
    "Choose an appropriate visualisation to create a visualisation of the data in your `lr_df` data frame from Q2. \n",
    "\n",
    "You can consult the lectures on visualisation and also use the following docs to help guide you and give you inspiration:\n",
    "* https://matplotlib.org/stable/plot_types/basic/index.html \n",
    "* https://realpython.com/pandas-plot-python/ \n",
    "* https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.html\n",
    "* https://www.w3schools.com/python/matplotlib_intro.asp \n",
    "\n",
    "Give a brief comment in the markdown box below about why you have chosen the visualisation you did, with reference to the type of data you are visualising. \n",
    "\n",
    "Also add a comment answering the question: \"Do you see any patterns in your visualisation of the data frame `lr_df`?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# please add your code for Q3 here (double click to edit)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Please add your written answers/comments for Q3 here (double-click to edit)**\n",
    "\n",
    "\"Why did you chose the visualisation you did, with reference to the type of data you are visualising?\"\n",
    "\n",
    "Your answer:\n",
    "\n",
    "\n",
    "\n",
    "\"Do you see any patterns in your visualisation of the data frame `lr_df`?\"\n",
    "\n",
    "Your answer:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4. [6 marks]\n",
    "\n",
    "For the *unit* environment statement for each university in our data, including Kent, (i.e. for all texts in the dictionaries unitb, unitw and unitk), perform the following pre-processing steps in this order:\n",
    "\n",
    "* tokenise the text using nltk.word_tokenize()\n",
    "* convert all text to lower case\n",
    "* perform POS-tagging using nltk.pos_tag()\n",
    "\n",
    "These steps will create a list of `POS-tagged tokens` for each university's unit environment statement. By `POS-tagged tokens`, this means tokens with tags indicating the relevant part of speech (POS). \n",
    "\n",
    "Using FreqDist, for each university's unit environment statement, calculate the frequency distribution for these POS-tagged tokens. (So you will calculate one frequency distribution per each university in our data.)\n",
    "\n",
    "Create a new dictionary called `fd` where the dictionary key is the university key (as in b_env, w_env and k_env), and the value is a list of the 10 most common `POS-tagged tokens` for that university's pre-processed unit environment statement.\n",
    "\n",
    "For example, if we have calculated a list of the 10 most common `POS-tagged tokens` from the pre-processed unit Environment statement for \"TheUniversityofBirmingham\", and stored that list in the list variable `mostCommon`, one possible way we could add this to the fd dictionary is:\n",
    "\n",
    "fd[\"TheUniversityofBirmingham\"] = mostCommon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fd = {}\n",
    "# please add your code for Q4 here (double-click to edit)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# please do not delete or edit this cell \n",
    "for f in fd:\n",
    "    print(f, fd[f])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q5. [2 marks] \n",
    "\n",
    "Looking at the original texts in `unitb`, `unitw` and `unitk`, suggest one extra pre-processing step you could do to improve the quality of this data. Briefly explain what that step is and why it would be useful. \n",
    "\n",
    "* You do not have to write the code to perform this step. * "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Please add your written answers/comments for Q5 here (double-click to edit)**\n",
    "\n",
    "What additional pre-processing step would you suggest and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End of part A. \n",
    "\n",
    "*Please submit this Jupyter notebook (or your Python file, as described above, if you preferred to work in a python file) as part of your submitted zip file.*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Please now see the coursework specification document on Moodle for Part B\n",
    "\n",
    "You are welcome to continue adding code/markdown comments to this file *below* this point, in cells below here, as you experiment with code for Part B. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "1322063094e41d3e3e06a7cc7d9093f553a57061e5bbe07182dbc0955a20ca1e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
